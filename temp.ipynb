{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# 创建模型和优化器\n",
    "model = MyModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 设置CyclicLR调度器\n",
    "step_size = 3\n",
    "base_lr = 0.001\n",
    "max_lr = 0.01\n",
    "cyclic_lr_scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "    optimizer,\n",
    "    base_lr=base_lr,\n",
    "    max_lr=max_lr,\n",
    "    step_size_up=step_size,\n",
    "    step_size_down=step_size * 2,\n",
    ")\n",
    "\n",
    "\n",
    "# 定义一个用于模拟训练的函数\n",
    "def train_model(num_epochs, num_batches_per_epoch):\n",
    "    learning_rates_batch = []\n",
    "    learning_rates_epoch = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # 记录学习率\n",
    "        learning_rates_epoch.append(optimizer.param_groups[0][\"lr\"])\n",
    "        for batch in range(num_batches_per_epoch):\n",
    "            learning_rates_batch.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "            # 更新CyclicLR调度器，在每个epoch结束时进行一次更新\n",
    "        cyclic_lr_scheduler.step()\n",
    "\n",
    "    learning_rates_epoch.append(optimizer.param_groups[0][\"lr\"])\n",
    "    return learning_rates_batch, learning_rates_epoch\n",
    "\n",
    "\n",
    "# 模拟训练过程，设置训练的epoch和每个epoch的batch数\n",
    "num_epochs = 5\n",
    "num_batches_per_epoch = 100\n",
    "\n",
    "learning_rates_batch, learning_rates_epoch = train_model(\n",
    "    num_epochs, num_batches_per_epoch\n",
    ")\n",
    "\n",
    "# 绘制学习率随着batch的变化曲线\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(len(learning_rates_batch)), learning_rates_batch)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"CyclicLR Learning Rate (Batch)\")\n",
    "plt.show()\n",
    "\n",
    "# 绘制学习率随着epoch的变化曲线\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(len(learning_rates_epoch)), learning_rates_epoch)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"CyclicLR Learning Rate (Epoch)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "imagenet_mean = torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1).cuda()\n",
    "imagenet_std = torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1).cuda()\n",
    "\n",
    "\n",
    "def generate_new_state_dict(state_dict):\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_state_dict[k.replace(\"model.\", \"\")] = v\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def pgd_attack(model, images, labels, eps=0.2, alpha=0.008, iters=40, device=\"cuda:0\"):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    ori_images = images.data\n",
    "\n",
    "    for i in range(iters):\n",
    "        images.requires_grad = True\n",
    "        outputs = model(images)\n",
    "\n",
    "        model.zero_grad()\n",
    "        cost = loss(outputs, labels).to(device)\n",
    "        cost.backward()\n",
    "\n",
    "        attack_images = images + alpha * images.grad.sign()\n",
    "        eta = torch.clamp(attack_images - ori_images, min=-eps, max=eps)\n",
    "        images = (ori_images + eta).detach_()\n",
    "    images = images * imagenet_std + imagenet_mean\n",
    "    images = torch.clamp(images, 0, 1)\n",
    "    return images\n",
    "\n",
    "\n",
    "import timm\n",
    "from dataset import *\n",
    "\n",
    "model = timm.create_model(\"resnet34\", pretrained=False, num_classes=1).cuda()\n",
    "model.load_state_dict(generate_new_state_dict(torch.load(\"./best.ckpt\")[\"state_dict\"]))\n",
    "model.eval()\n",
    "train_data_loader = get_dataloader(transform=test_transform, bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, label) in enumerate(train_data_loader):\n",
    "    img, label = img.cuda(), label.cuda()\n",
    "    result = pgd_attack(model, img, label)\n",
    "    label = label.cpu().numpy()[0][0]\n",
    "    cv2.imwrite(\n",
    "        f\"./phase2/{i:05d}_{int(label)}.jpg\",\n",
    "        result[0].permute(1, 2, 0).cpu().numpy() * 255,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./phase2/00058_1.jpg\")\n",
    "img = test_transform(image=img)[\"image\"]\n",
    "torch.sigmoid(model(img.unsqueeze(0).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "paths = [\n",
    "    \"./LiveDetect/allmixup+randomcropresize0.64+noshuffle5fold_0/last.ckpt\",\n",
    "    \"./LiveDetect/allmixup+randomcropresize0.64+noshuffle5fold_1/last.ckpt\",\n",
    "    \"./LiveDetect/allmixup+randomcropresize0.64+noshuffle5fold_2/last.ckpt\",\n",
    "    \"./LiveDetect/allmixup+randomcropresize0.64+noshuffle5fold_3/epoch=119-valid_acer=0.0124.ckpt\",\n",
    "    \"./LiveDetect/allmixup+randomcropresize0.64+noshuffle5fold_4/last.ckpt\",\n",
    "]\n",
    "ckpts = []\n",
    "for i, path in enumerate(paths):\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    ckpts.append(ckpt[\"state_dict\"])\n",
    "for i, ckpt in enumerate(ckpts):\n",
    "    torch.save(ckpt, f\"./modelsoups/{i}.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
